{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSM-MCMC\n",
    "\n",
    "## Method of Simulated Moments using Markov Chain Monte Carlo\n",
    "\n",
    "If you are a new user of the package MSM.jl, see [this notebook](https://github.com/JulienPascal/MSM.jl/tree/main/notebooks) first. \n",
    "\n",
    "In this notebook, we use the **Laplace Type Estimator** formulation of GMM by [Chernozhukov and Hong (2003](https://www.sciencedirect.com/science/article/abs/pii/S0304407603001003) in the context of the Method of Simulated Moments.\n",
    "\n",
    "In a nuthsell, we transform the problem of maximizing the MSM objective function into the problem of maximizing a **quasi-posterior**. Hence **Markov Chain Monte Carlo** (or posterior simulation methods) can be used.\n",
    "\n",
    "I use [AffineInvariantMCMC](https://github.com/madsjulia/AffineInvariantMCMC.jl) because it can run the MCMC algorithm in parallel on a cluster.\n",
    "\n",
    "---\n",
    "\n",
    "The notebook does not run correctly? run the file [LTE.jl](https://github.com/JulienPascal/MSM.jl/blob/main/notebooks/LTE.jl) directly\n",
    "\n",
    "```bash\n",
    "julia LTE.jl\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using ClusterManagers\n",
    "using Distributed\n",
    "\n",
    "OnCluster = false #set to false to run locally\n",
    "addWorkers = true #set to false to run serially\n",
    "println(\"OnCluster = $(OnCluster)\")\n",
    "\n",
    "# Current number of workers\n",
    "#--------------------------\n",
    "currentWorkers = nworkers()\n",
    "println(\"Initial number of workers = $(currentWorkers)\")\n",
    "\n",
    "# Increase the number of workers available\n",
    "#-----------------------------------------\n",
    "maxNumberWorkers = 10\n",
    "if addWorkers == true\n",
    "\tif OnCluster == true\n",
    "\t  addprocs(SlurmManager(maxNumberWorkers))\n",
    "\telse\n",
    "\t  addprocs(maxNumberWorkers)\n",
    "\tend\n",
    "end\n",
    "\n",
    "\n",
    "# Sanity checks\n",
    "#-------------\n",
    "hosts = []\n",
    "pids = []\n",
    "for i in workers()\n",
    "\thost, pid = fetch(@spawnat i (gethostname(), getpid()))\n",
    "\tprintln(\"Hello I am worker $(i), my host is $(host)\")\n",
    "\tpush!(hosts, host)\n",
    "\tpush!(pids, pid)\n",
    "end\n",
    "\n",
    "currentWorkers = nworkers()\n",
    "println(\"Number of workers = $(currentWorkers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using ParallelDataTransfer\n",
    "using DataFrames\n",
    "using RobustPmap #Necessary for AffineInvariantMCMC\n",
    "using CSV\n",
    "@everywhere using MSM\n",
    "@everywhere using DataStructures\n",
    "@everywhere using OrderedCollections\n",
    "@everywhere using Distributions\n",
    "@everywhere using Random\n",
    "@everywhere using DataStructures\n",
    "@everywhere using Statistics\n",
    "@everywhere using LinearAlgebra\n",
    "@everywhere using AffineInvariantMCMC\n",
    "@everywhere using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulated data\n",
    "Random.seed!(1234)  #for replicability reasons\n",
    "T = 100000          #number of periods\n",
    "P = 2               #number of dependent variables\n",
    "beta0 = rand(P)     #choose true coefficients by drawing from a uniform distribution on [0,1]\n",
    "alpha0 = rand(1)[]  #intercept\n",
    "theta0 = 0.0        #coefficient to create serial correlation in the error terms\n",
    "println(\"True intercept = $(alpha0)\")\n",
    "println(\"True coefficient beta0 = $(beta0)\")\n",
    "println(\"Serial correlation coefficient theta0 = $(theta0)\")\n",
    "\n",
    "# Generation of error terms\n",
    "# row = individual dimension\n",
    "# column = time dimension \n",
    "U = zeros(T)\n",
    "d = Normal()\n",
    "U[1] = rand(d, 1)[] #first error term\n",
    "# loop over time periods\n",
    "for t = 2:T\n",
    "    U[t] = rand(d, 1)[] + theta0*U[t-1]\n",
    "end\n",
    "\n",
    "# Let's simulate the dependent variables x_t\n",
    "x = zeros(T, P)\n",
    "\n",
    "d = Uniform(0, 5)\n",
    "for p = 1:P  \n",
    "    x[:,p] = rand(d, T)\n",
    "end\n",
    "\n",
    "# Let's calculate the resulting y_t\n",
    "y = zeros(T)\n",
    "\n",
    "for t=1:T\n",
    "    y[t] = alpha0 + x[t,1]*beta0[1] + x[t,2]*beta0[2] + U[t]\n",
    "end\n",
    "\n",
    "# Send simulated data to workers\n",
    "sendto(workers(), y=y)\n",
    "sendto(workers(), x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "p1 = scatter(x[1:100,1], y[1:100], xlabel = \"x1\", ylabel = \"y\", legend=:none, smooth=true)\n",
    "p2 = scatter(x[1:100,2], y[1:100], xlabel = \"x2\", ylabel = \"y\", legend=:none, smooth=true)\n",
    "plot(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define locally\n",
    "myProblem = MSMProblem(options = MSMOptions(maxFuncEvals=1000, globalOptimizer = :dxnes, localOptimizer = :NelderMead));\n",
    "\n",
    "# Send to workers\n",
    "sendto(workers(), myProblem=myProblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors\n",
    "dictPriors = OrderedDict{String,Array{Float64,1}}()\n",
    "dictPriors[\"alpha\"] = [0.5, 0.001, 1.0]\n",
    "dictPriors[\"beta1\"] = [0.5, 0.001, 1.0]\n",
    "dictPriors[\"beta2\"] = [0.5, 0.001, 1.0]\n",
    "\n",
    "# Empirical moments\n",
    "dictEmpiricalMoments = OrderedDict{String,Array{Float64,1}}()\n",
    "dictEmpiricalMoments[\"mean\"] = [mean(y); mean(y)] #informative on the intercept\n",
    "dictEmpiricalMoments[\"mean^2\"] = [mean(y.^2); mean(y.^2)] #informative on the intercept\n",
    "dictEmpiricalMoments[\"mean^3\"] = [mean(y.^3); mean(y.^3)] #informative on the intercept\n",
    "dictEmpiricalMoments[\"var\"] = [mean(y.^2) - mean(y)^2; mean(y.^2) - mean(y)^2] \n",
    "dictEmpiricalMoments[\"mean_x1y\"] = [mean(x[:,1] .* y); mean(x[:,1] .* y)] #informative on betas\n",
    "dictEmpiricalMoments[\"mean_x2y\"] = [mean(x[:,2] .* y); mean(x[:,2] .* y)] #informative on betas\n",
    "dictEmpiricalMoments[\"mean_x1y^2\"] = [mean((x[:,1] .* y).^2); mean((x[:,1] .* y).^2)] #informative on betas\n",
    "dictEmpiricalMoments[\"mean_x2y^2\"] = [mean((x[:,2] .* y).^2); mean((x[:,2] .* y).^2)] #informative on betas\n",
    "\n",
    "# Send to workers\n",
    "sendto(workers(), dictPriors=dictPriors)\n",
    "sendto(workers(), dictEmpiricalMoments=dictEmpiricalMoments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere set_priors!(myProblem, dictPriors)\n",
    "@everywhere set_empirical_moments!(myProblem, dictEmpiricalMoments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[1] corresponds to the intercept, x[2] corresponds to beta1, x[3] corresponds to beta2\n",
    "@everywhere function functionLinearModel(x; uniform_draws::Array{Float64,1}, simX::Array{Float64,2}, nbDraws::Int64 = length(uniform_draws), burnInPerc::Int64 = 10)\n",
    "    T = nbDraws\n",
    "    P = 2       #number of dependent variables\n",
    "\n",
    "    alpha = x[1]\n",
    "    beta = x[2:end]\n",
    "    theta = 0.0     #coefficient to create serial correlation in the error terms\n",
    "\n",
    "    # Creation of error terms\n",
    "    # row = individual dimension\n",
    "    # column = time dimension\n",
    "    U = zeros(T)\n",
    "    d = Normal()\n",
    "    # Inverse cdf (i.e. quantile)\n",
    "    gaussian_draws = quantile.(d, uniform_draws)\n",
    "    U[1] = gaussian_draws[1] #first error term\n",
    "\n",
    "    # loop over time periods\n",
    "    for t = 2:T\n",
    "        U[t] = gaussian_draws[t] + theta*U[t-1]\n",
    "    end\n",
    "\n",
    "    # Let's calculate the resulting y_t\n",
    "    y = zeros(T)\n",
    "\n",
    "    for t=1:T\n",
    "        y[t] = alpha + simX[t,1]*beta[1] + simX[t,2]*beta[2] + U[t]\n",
    "    end\n",
    "\n",
    "    # Get rid of the burn-in phase:\n",
    "    #------------------------------\n",
    "    startT = div(nbDraws, burnInPerc)\n",
    "\n",
    "    # Moments:\n",
    "    #---------\n",
    "    output = OrderedDict{String,Float64}()\n",
    "    output[\"mean\"] = mean(y[startT:nbDraws])\n",
    "    output[\"mean^2\"] = mean(y[startT:nbDraws].^2)\n",
    "    output[\"mean^3\"] = mean(y[startT:nbDraws].^3)\n",
    "    output[\"var\"] = mean(y[startT:nbDraws].^2) - mean(y[startT:nbDraws])^2 \n",
    "    output[\"mean_x1y\"] = mean(simX[startT:nbDraws,1] .* y[startT:nbDraws])\n",
    "    output[\"mean_x2y\"] = mean(simX[startT:nbDraws,2] .* y[startT:nbDraws])\n",
    "    output[\"mean_x1y^2\"] = mean((simX[startT:nbDraws,1] .* y[startT:nbDraws]).^2)\n",
    "    output[\"mean_x2y^2\"] = mean((simX[startT:nbDraws,2] .* y[startT:nbDraws]).^2)\n",
    "\n",
    "    return output\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's freeze the randomness during the minimization\n",
    "d_Uni = Uniform(0,1)\n",
    "nbDraws = 10000 #Number of draws in the simulated data\n",
    "burnInPerc = 10 #Burn-in phase (10%). Not necessary in the present context.\n",
    "startT = div(nbDraws, burnInPerc) #First period used to calculate moments on simulated data\n",
    "NMSM = nbDraws - startT + 1; #Number of Draws used when calculated moments on simulated data\n",
    "uniform_draws = rand(d_Uni, nbDraws)\n",
    "simX = zeros(length(uniform_draws), 2)\n",
    "d = Uniform(0, 5)\n",
    "for p = 1:2\n",
    "  simX[:,p] = rand(d, length(uniform_draws))\n",
    "end\n",
    "\n",
    "# Send to workers\n",
    "sendto(workers(), burnInPerc=burnInPerc)\n",
    "sendto(workers(), simX=simX)\n",
    "sendto(workers(), uniform_draws=uniform_draws)\n",
    "\n",
    "# Construct the objective function everywhere\n",
    "@everywhere set_simulate_empirical_moments!(myProblem, x -> functionLinearModel(x, uniform_draws = uniform_draws, simX = simX, burnInPerc=burnInPerc))\n",
    "@everywhere construct_objective_function!(myProblem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Safety check: value on the master node == values on slave nodes?\n",
    "using Test\n",
    "val_local = myProblem.objective_function(ones(3)); #local execution\n",
    "val_workers = [];\n",
    "for w in workers() #Execution on workers\n",
    "    push!(val_workers, @fetchfrom w myProblem.objective_function(ones(3)))\n",
    "end\n",
    "for (wIndex, w) in enumerate(workers())\n",
    "    @test abs(val_local - val_workers[wIndex]) < 10e-10\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain Monte Carlo\n",
    "\n",
    "#### Tuning Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Formulate the problem as a Laplace Type Estimator and use MCMC to find\n",
    "# the quasi-posterior median\n",
    "#------------------------------------------------------------------------------\n",
    "# For tuning parameters, see: See https://github.com/madsjulia/AffineInvariantMCMC.jl\n",
    "@everywhere begin\n",
    "\tnumdims = 3\n",
    "\tnumwalkers = 10\n",
    "\tthinning = 10\n",
    "\tnumsamples_perwalker = 10000\n",
    "\tburnin = Int((1/10)*numsamples_perwalker)\n",
    "\tlb = 0 .* ones(numdims) #lower bound\n",
    "\tub = 1 .* ones(numdims) #upper bound\n",
    "\t# Uniform prior\n",
    "\t# d_prior = Product(Uniform.(lb, ub))\n",
    "\t# Normal\n",
    "\td_prior = MvNormal(zeros(numdims), 0.1 .* I(numdims))\n",
    "end\n",
    "\n",
    "# Pseudo Log-likelihood\n",
    "@everywhere function Ln_MSM(x, NMSM)\n",
    "\treturn -0.5*NMSM*myProblem.objective_function(x)\n",
    "end\n",
    "\n",
    "# Pseudo Log quasi-posterior: Pseudo Log(likelihood) + log(prior)\n",
    "@everywhere function quasi_posterior(x, NMSM, d_prior)\n",
    "\t return Ln_MSM(x, NMSM) + log(pdf(d_prior, x))\n",
    "end\n",
    "\n",
    "\n",
    "# Safety check: value on the master node == values on slave nodes?\n",
    "using Test\n",
    "val_local = Ln_MSM(ones(3), NMSM); #local execution\n",
    "val_workers = [];\n",
    "for w in workers() #Execution on workers\n",
    "    push!(val_workers, @fetchfrom w Ln_MSM(ones(3), NMSM))\n",
    "end\n",
    "for (wIndex, w) in enumerate(workers())\n",
    "    @test abs(val_local - val_workers[wIndex]) < 10e-10\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCMC\n",
    "\n",
    "See [AffineInvariantMCMC.jl](https://github.com/madsjulia/AffineInvariantMCMC.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly perturb the initial draws for the walkers\n",
    "x0 = [dictPriors[k][1] for k in keys(dictPriors)]\n",
    "x0_chains = ones(numdims, numwalkers).*true_vals .+ rand(numdims, numwalkers) .* 1.0\n",
    "chain, llhoodvals = AffineInvariantMCMC.sample(x -> quasi_posterior(x, nbDraws, d_prior), numwalkers, x0_chains, burnin, 1)\n",
    "chain, llhoodvals = AffineInvariantMCMC.sample(x -> quasi_posterior(x, nbDraws, d_prior), numwalkers, chain[:, :, end], numsamples_perwalker, thinning)\n",
    "flatchain, flatllhoodvals = AffineInvariantMCMC.flattenmcmcarray(chain, llhoodvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Plot Draws\n",
    "#-------------------------------------------------------------------------------\n",
    "p1 = plot(flatchain[1,:], ylabel=\"alpha0\", xlabel=\"T\", legend=:none)\n",
    "p2 = plot(flatchain[2,:], ylabel=\"beta1\", xlabel=\"T\", legend=:none)\n",
    "p3 = plot(flatchain[3,:], ylabel=\"beta2\", xlabel=\"T\", legend=:none)\n",
    "p4 = plot(p1, p2, p3)\n",
    "savefig(p4, joinpath(pwd(),\"chains_MSM_MCMC.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh1 = histogram(flatchain[1,burnin:end], title=\"alpha0\", legend=:none)\n",
    "vline!(hh1, [alpha0[1]], linewidth = 4)\n",
    "hh2 = histogram(flatchain[2,burnin:end], title=\"beta1\", legend=:none)\n",
    "vline!(hh2, [beta0[1]], linewidth = 4)\n",
    "hh3 = histogram(flatchain[3,burnin:end], title=\"beta2\", legend=:none)\n",
    "vline!(hh3, [beta0[2]], linewidth = 4)\n",
    "hh4 = plot(hh1, hh2, hh3)\n",
    "savefig(hh4, joinpath(pwd(),\"histograms_MSM_MCMC.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results with GLM\n",
    "using DataFrames, GLM\n",
    "data = DataFrame(x1=x[:,1], x2=x[:,2], y= y[:]);\n",
    "ols = lm(@formula(y ~ x1 + x2), data)\n",
    "coef_ols = coef(ols)\n",
    "ci_ols = confint(ols)\n",
    "stderror_ols = stderror(ols)\n",
    "\n",
    "result_alpha0 = append!(quantile(flatchain[1,burnin:end],[0.05, 0.10, 0.5, 0.90, 0.95]), std(flatchain[1,burnin:end]), NaN, alpha0[1],NaN, coef_ols[1], ci_ols[1,1], ci_ols[1,2], stderror_ols[1])\n",
    "result_beta1 = append!(quantile(flatchain[2,burnin:end],[0.05, 0.10, 0.5, 0.90, 0.95]), std(flatchain[2,burnin:end]), NaN,beta0[1], NaN,coef_ols[2], ci_ols[2,1], ci_ols[2,2], stderror_ols[2])\n",
    "result_beta2 = append!(quantile(flatchain[3,burnin:end],[0.05, 0.10, 0.5, 0.90, 0.95]), std(flatchain[3,burnin:end]), NaN,beta0[2], NaN,coef_ols[3], ci_ols[3,1], ci_ols[3,2], stderror_ols[3])\n",
    "results = DataFrame(variable = [\"P5\"; \"P10\"; \"Median\"; \"P90\"; \"P95\"; \"std\"; \"-\" ;\"True value\"; \"-\" ;\"OLS Estimate\"; \"P5 OLS\"; \"P95 OLS\"; \"Std OLS\"],\n",
    "\t\t\t\t\t\talpha0 = result_alpha0, beta1 = result_beta1, beta2 = result_beta2)\n",
    "\n",
    "CSV.write(joinpath(pwd(),\"output_table_MSM_MCMC.csv\"), results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
